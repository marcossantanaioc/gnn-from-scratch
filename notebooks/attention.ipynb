{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9fc53d-e641-4ec6-9bf0-f633886547d1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0fd007-44df-42d6-b25b-2e4545a7ee55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data as torch_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from typing import Final\n",
    "import pandas as pd\n",
    "import dataclasses\n",
    "from etils import epath\n",
    "import torch_scatter\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "from graphmodels import featurizer\n",
    "from graphmodels import constants\n",
    "from graphmodels import datasets\n",
    "from graphmodels import data_utils\n",
    "from graphmodels import models\n",
    "from graphmodels.layers import graph_attention_layers\n",
    "from graphmodels.models import gat\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn import model_selection as sk_modelselection\n",
    "from sklearn import metrics as sk_metrics\n",
    "\n",
    "from torch_geometric import nn as geom_nn\n",
    "from torch_geometric.loader import DataLoader as GeomDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.nn import models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.drawOptions.addAtomIndices = True\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d197bc-b471-462b-8fd3-2532ac744bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATAPATH: epath.Path = epath.Path(\"../datasets/chemistry/\")\n",
    "df = pd.read_csv(DATAPATH/\"delaney-processed_clean.csv\")\n",
    "df[\"mol\"] = df[\"RDKIT_SMILES\"].apply(Chem.MolFromSmiles)\n",
    "df[\"num_bonds\"] = df[\"mol\"].apply(lambda x : x.GetNumBonds())\n",
    "df = df.loc[df[\"num_bonds\"]>=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b21fb41-bb45-40de-ac0b-d646afade668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, test_df = sk_modelselection.train_test_split(\n",
    "    df, test_size=0.3, random_state=42, shuffle=True,\n",
    "    #stratify=df[\"measured log solubility in mols per litre\"]\n",
    ")\n",
    "train_df, valid_df = sk_modelselection.train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    #stratify=train_df[\"measured log solubility in mols per litre\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dce251-d931-423e-9349-ba9248b78136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL: str = \"measured log solubility in mols per litre\"\n",
    "SMILES: str = \"smiles\"\n",
    "train_dset = datasets.mpnn_dataset.MPNNDataset(smiles=tuple(train_df[SMILES]),\n",
    "                                               targets=tuple(train_df[LABEL]),\n",
    "                                 add_master_node=False)\n",
    "\n",
    "valid_dset = datasets.mpnn_dataset.MPNNDataset(smiles=tuple(valid_df[SMILES]),\n",
    "                                               targets=tuple(valid_df[LABEL]),\n",
    "                                 add_master_node=False)\n",
    "\n",
    "test_dset = datasets.mpnn_dataset.MPNNDataset(smiles=tuple(test_df[SMILES]),\n",
    "                                               targets=tuple(test_df[LABEL]),\n",
    "                                add_master_node=False)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dset,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=data_utils.mpnn_collate_diag,\n",
    "                             )\n",
    "\n",
    "valid_dataloader = DataLoader(dataset=valid_dset,\n",
    "                              batch_size=32,\n",
    "                              shuffle=False,\n",
    "                              collate_fn=data_utils.mpnn_collate_diag,\n",
    "                             )\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dset,\n",
    "                              batch_size=32,\n",
    "                              shuffle=False,\n",
    "                              collate_fn=data_utils.mpnn_collate_diag,\n",
    "                            )\n",
    "\n",
    "\n",
    "#dataset = TUDataset(root='/tmp/PROTEINS', name='PROTEINS')\n",
    "# train_dset = PPI(root='/tmp/PPI', split='train')\n",
    "# val_dset = PPI(root='/tmp/PPI', split='val')\n",
    "# test_dset = PPI(root='/tmp/PPI', split='test')\n",
    "\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = GeomDataLoader(train_dset, batch_size=16, shuffle=True)\n",
    "# val_loader = GeomDataLoader(val_dset, batch_size=32, shuffle=False)\n",
    "# test_loader = GeomDataLoader(test_dset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # Extract labels for stratified splitting\n",
    "# labels = [data.y.item() for data in dataset]\n",
    "\n",
    "# # First split: train vs temp (val + test)\n",
    "# train_idx, temp_idx = sk_modelselection.train_test_split(\n",
    "#     list(range(len(dataset))),\n",
    "#     test_size=0.3,\n",
    "#     stratify=labels,\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# # Second split: val vs test from temp\n",
    "# temp_labels = [labels[i] for i in temp_idx]\n",
    "# val_idx, test_idx = sk_modelselection.train_test_split(\n",
    "#     temp_idx,\n",
    "#     test_size=0.5,\n",
    "#     stratify=temp_labels,\n",
    "#     random_state=42,\n",
    "# )\n",
    "\n",
    "# # Create the datasets\n",
    "# train_dataset = dataset[train_idx]\n",
    "# val_dataset = dataset[val_idx]\n",
    "# test_dataset = dataset[test_idx]\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = GeomDataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# val_loader = GeomDataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "# test_loader = GeomDataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d172787-e330-4fd2-ab52-80ba62a0e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3088f9d6-314a-46c7-9db6-f018cc006da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([504, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = graph_attention_layers.MultiHeadGATLayer(n_node_features=136, apply_act=False, dropout=0.25, n_hidden_features=64, num_heads=8, scaling=0.2)\n",
    "layer(first_batch.node_features, first_batch.edge_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b48c67c-1531-4252-bb2e-5347e0db27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from jaxtyping import Float, Int\n",
    "from jaxtyping import jaxtyped as jt\n",
    "from torch import nn\n",
    "from typeguard import typechecked as typechecker\n",
    "\n",
    "from graphmodels.layers import graph_attention_layers\n",
    "from graphmodels.models import constants as model_constants\n",
    "\n",
    "\n",
    "@jt(typechecker=typechecker)\n",
    "class GATModel(nn.Module):\n",
    "    \"\"\"Implements a Graph Attention Network (GAT).\n",
    "\n",
    "    This model consists of a stack of GAT layers with skip connections.\n",
    "    Only node features are supported in this implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_node_features: int,\n",
    "        n_hidden_features: int,\n",
    "        n_out_channels: int,\n",
    "        num_layers: int,\n",
    "        num_heads: int,\n",
    "        scaling: float,\n",
    "        dropout: float,\n",
    "        output_level: model_constants.OutputLevel | str,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if output_level not in model_constants.ALLOWED_OUTPUT_LEVEL:\n",
    "            raise ValueError(f\"{output_level} isnt a valid output.\")\n",
    "\n",
    "        self.output_level = output_level\n",
    "\n",
    "        gat_layers = [graph_attention_layers.MultiHeadGATLayer(\n",
    "                    n_node_features=n_node_features,\n",
    "                    n_hidden_features=n_hidden_features,\n",
    "                    num_heads=num_heads,\n",
    "                    dropout=dropout,\n",
    "                    scaling=scaling,\n",
    "                    apply_act=True)]\n",
    "\n",
    "        for i in range(num_layers-1):\n",
    "            gat_layers.append(graph_attention_layers.MultiHeadGATLayer(\n",
    "                    n_node_features=n_hidden_features,\n",
    "                    n_hidden_features=n_hidden_features,\n",
    "                    num_heads=num_heads,\n",
    "                    dropout=dropout,\n",
    "                    scaling=scaling,\n",
    "                    apply_act=True,\n",
    "                ))\n",
    "\n",
    "        self.conv_layers = nn.ModuleList(gat_layers)\n",
    "\n",
    "        self.output_layer = graph_attention_layers.MultiHeadGATLayer(\n",
    "            n_node_features=n_hidden_features,\n",
    "            n_hidden_features=n_out_channels,\n",
    "            num_heads=1,\n",
    "            dropout=dropout,\n",
    "            scaling=scaling,\n",
    "            apply_act=False,\n",
    "        )\n",
    "\n",
    "    def readout(\n",
    "        self,\n",
    "        x: Float[torch.Tensor, \"nodes features\"],\n",
    "        edge_index: Int[torch.Tensor, \"2 edges\"],\n",
    "        batch_vector: Int[torch.Tensor, \" batch\"],\n",
    "    ) -> Float[torch.Tensor, \"out n_out_channels\"]:\n",
    "        \n",
    "        emb_dim = x.size(-1)\n",
    "        num_batches = int(batch_vector.max()) + 1\n",
    "        \n",
    "        if self.output_level == model_constants.OutputLevel.GRAPH:\n",
    "            mol_embeddings = torch.zeros(\n",
    "                num_batches,\n",
    "                emb_dim,\n",
    "                device=x.device,\n",
    "            )\n",
    "\n",
    "            mol_embeddings.index_add_(0, batch_vector, x)\n",
    "\n",
    "            return mol_embeddings\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_features: Float[torch.Tensor, \"nodes node_features\"],\n",
    "        edge_index: Int[torch.Tensor, \"2 edges\"],\n",
    "        batch_vector: Int[torch.Tensor, \" batch\"],\n",
    "    ) -> Float[torch.Tensor, \"out n_out_channels\"]:\n",
    "\n",
    "        for layer in self.conv_layers:\n",
    "            \n",
    "            node_features = layer(\n",
    "                node_features=node_features,\n",
    "                edge_index=edge_index,\n",
    "            )\n",
    "\n",
    "        out = self.output_layer(node_features, edge_index)\n",
    "        return self.readout(out, edge_index, batch_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c6c2b15-41d5-43ed-8bd9-b915fefd38b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1]), torch.Size([504, 136]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GATModel(n_node_features=136, n_hidden_features=255, n_out_channels=1, dropout=0.25, num_heads=3, num_layers=5, scaling=0.2, output_level=\"graph\")\n",
    "out = model(node_features=first_batch.node_features, edge_index=first_batch.edge_index, batch_vector=first_batch.batch_vector)\n",
    "out.shape, first_batch.node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "178591b9-59b1-46e9-8527-603a2f3644a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7260],\n",
       "        [ 1.4188],\n",
       "        [-5.2592],\n",
       "        [ 1.6417],\n",
       "        [ 0.0660],\n",
       "        [-1.3101],\n",
       "        [ 4.7412],\n",
       "        [-1.0956],\n",
       "        [ 2.4441],\n",
       "        [ 0.2318],\n",
       "        [ 4.0344],\n",
       "        [ 1.3035],\n",
       "        [-1.4586],\n",
       "        [ 0.8494],\n",
       "        [ 3.4144],\n",
       "        [-6.1151],\n",
       "        [ 1.2773],\n",
       "        [-0.7131],\n",
       "        [ 1.6294],\n",
       "        [ 1.4579],\n",
       "        [ 2.7853],\n",
       "        [ 1.3618],\n",
       "        [ 2.4237],\n",
       "        [ 3.4000],\n",
       "        [ 3.1446],\n",
       "        [-5.9464],\n",
       "        [ 5.5217],\n",
       "        [10.0874],\n",
       "        [-4.6524],\n",
       "        [-1.6082],\n",
       "        [ 9.5441],\n",
       "        [-6.9917]], grad_fn=<IndexAddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3720e683-63f3-4e10-9834-21af55c10660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 255])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffe453bc-2bf8-41a8-9bf9-2af1fbed30cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 32 is out of bounds for dimension 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cheminformatics-env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cheminformatics-env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/gnn-from-scratch/graphmodels/layers/graph_attention_layers.py:419\u001b[39m, in \u001b[36mMultiHeadGATLayer.forward\u001b[39m\u001b[34m(self, node_features, edge_index)\u001b[39m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    414\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    415\u001b[39m     node_features: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mnodes node_features\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    416\u001b[39m     edge_index: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33m2 edges\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    417\u001b[39m ) -> Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mnodes node_features\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    418\u001b[39m     heads_nodes_out = [\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m         \u001b[43mattn_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m attn_head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.multiheadgat\n\u001b[32m    421\u001b[39m     ]\n\u001b[32m    422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(heads_nodes_out, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cheminformatics-env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/cheminformatics-env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/gnn-from-scratch/graphmodels/layers/graph_attention_layers.py:119\u001b[39m, in \u001b[36mGraphAttentionLayerSkip.forward\u001b[39m\u001b[34m(self, node_features, edge_index)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    105\u001b[39m     node_features: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mnodes node_features\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    106\u001b[39m     edge_index: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33m2 edges\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    107\u001b[39m ) -> Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mnodes node_features\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    108\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Performs the forward pass.\u001b[39;00m\n\u001b[32m    109\u001b[39m \n\u001b[32m    110\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    118\u001b[39m     message, transformed_node_features, target_nodes = (\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m            \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     )\n\u001b[32m    124\u001b[39m     out = torch_scatter.scatter_add(\n\u001b[32m    125\u001b[39m         message,\n\u001b[32m    126\u001b[39m         target_nodes,\n\u001b[32m    127\u001b[39m         dim=\u001b[32m0\u001b[39m,\n\u001b[32m    128\u001b[39m         dim_size=transformed_node_features.size(\u001b[32m0\u001b[39m),\n\u001b[32m    129\u001b[39m     )\n\u001b[32m    130\u001b[39m     out = out + transformed_node_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/gnn-from-scratch/graphmodels/layers/graph_attention_layers.py:85\u001b[39m, in \u001b[36mGraphAttentionLayerSkip.compute_attention\u001b[39m\u001b[34m(self, node_features, edge_index)\u001b[39m\n\u001b[32m     82\u001b[39m neighbors_nodes = edge_index[\u001b[32m1\u001b[39m]\n\u001b[32m     83\u001b[39m target_nodes = edge_index[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m h_i = \u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_nodes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     87\u001b[39m h_j = h[neighbors_nodes]\n\u001b[32m     88\u001b[39m h_concat = torch.cat([h_i, h_j], dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 32 is out of bounds for dimension 0 with size 32"
     ]
    }
   ],
   "source": [
    "model.output_layer(out, first_batch.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e899a7-b1c0-4a46-963f-ef971fd00ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 255])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1a6ace-22c2-4b2e-86bd-cd21bc4b9ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module,\n",
    "                train_loader: DataLoader,\n",
    "                valid_loader: DataLoader,\n",
    "                loss_fn: torch.nn.modules.loss,\n",
    "                epochs: int=10,\n",
    "                lr: float=1e-3,\n",
    "                max_learning_rate: float=1e-2,\n",
    "                weight_decay: float=0.1,\n",
    "                device: str='cuda'):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_learning_rate, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "    \n",
    "    history = []\n",
    "\n",
    "    model.to(device)\n",
    "    print(\"ðŸš€ Starting training...\\n\")\n",
    "    pbar = tqdm(total=epochs, desc=\"Training\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, train_batch in enumerate(train_loader):\n",
    "            atom_feats = train_batch.x.to(device)\n",
    "            #bond_features =  batch.edge_features.to(device)\n",
    "            edge_index = train_batch.edge_index.to(device)\n",
    "            labels = train_batch.y.to(device)\n",
    "            batch_vector = train_batch.batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(node_features=atom_feats, edge_index=edge_index, batch_vector=batch_vector).squeeze()\n",
    "\n",
    "            loss = loss_fn(outputs, labels.squeeze().to(torch.float32))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        valid_batch_loss = []\n",
    "        with torch.no_grad():\n",
    "            for valid_batch_idx, val_batch in enumerate(valid_loader):\n",
    "                atom_feats = val_batch.x.to(device)\n",
    "                #bond_features =  batch.edge_features.to(device)\n",
    "                edge_index = val_batch.edge_index.to(device)\n",
    "                labels = val_batch.y.to(device)\n",
    "                batch_vector = val_batch.batch.to(device)\n",
    "\n",
    "                outputs = model(node_features=atom_feats, edge_index=edge_index, batch_vector=batch_vector).squeeze()\n",
    "                loss = loss_fn(outputs, labels.squeeze().to(torch.float32))\n",
    "                valid_loss += loss.item()\n",
    "        valid_loss /= len(valid_loader)\n",
    "\n",
    "        # Update the tqdm progress bar with train and validation loss\n",
    "        pbar.set_postfix({\"train_loss\": f\"{train_loss:.4f}\", \"val_loss\": f\"{valid_loss:.4f}\"})\n",
    "\n",
    "        history.append({'epoch': epoch+1, 'train_loss': train_loss, 'valid_loss': valid_loss})\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    print(\"\\nðŸŽ‰ Training completed!\\n\")\n",
    "    return pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4bd5edf-2013-4ebf-bd4c-3a858944eb32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0da9674ec604a419d3e171adf48b81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 3.63 GiB of which 179.00 MiB is free. Including non-PyTorch memory, this process has 2.71 GiB memory in use. Of the allocated memory 2.48 GiB is allocated by PyTorch, and 164.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m gat_model \u001b[38;5;241m=\u001b[39m SimpleGATModel(n_node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     10\u001b[0m                            n_hidden_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     11\u001b[0m                            n_out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m121\u001b[39m,\n\u001b[1;32m     12\u001b[0m                           )\n\u001b[1;32m     13\u001b[0m                            \u001b[38;5;66;03m#dropout=0.1)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#geom_model = models.GAT(in_channels=3, hidden_channels=12, num_layers=1, out_channels=1)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#geom_model = GATGraphClassifier(in_channels=3, hidden_channels=12, num_layers=3, out_channels=1)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m train_model(model\u001b[38;5;241m=\u001b[39mgat_model,\n\u001b[1;32m     18\u001b[0m                       loss_fn\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(),\n\u001b[1;32m     19\u001b[0m                       train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m     20\u001b[0m                       valid_loader\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[1;32m     21\u001b[0m                       epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     22\u001b[0m                       lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m,\n\u001b[1;32m     23\u001b[0m                       max_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-3\u001b[39m,\n\u001b[1;32m     24\u001b[0m                      weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m     25\u001b[0m                       device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, loss_fn, epochs, lr, max_learning_rate, weight_decay, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m batch_vector \u001b[38;5;241m=\u001b[39m train_batch\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(node_features\u001b[38;5;241m=\u001b[39matom_feats, edge_index\u001b[38;5;241m=\u001b[39medge_index, batch_vector\u001b[38;5;241m=\u001b[39mbatch_vector)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m, in \u001b[0;36mSimpleGATModel.forward\u001b[0;34m(self, node_features, edge_index, batch_vector)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, node_features, edge_index, batch_vector):\n\u001b[0;32m---> 22\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_layer1(node_features\u001b[38;5;241m=\u001b[39mnode_features, edge_index\u001b[38;5;241m=\u001b[39medge_index)\n\u001b[1;32m     23\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_layer2(node_features\u001b[38;5;241m=\u001b[39mout, edge_index\u001b[38;5;241m=\u001b[39medge_index)\n\u001b[1;32m     24\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_layer3(node_features\u001b[38;5;241m=\u001b[39mout, edge_index\u001b[38;5;241m=\u001b[39medge_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 194\u001b[0m, in \u001b[0;36mGraphAttentionLayerV3.forward\u001b[0;34m(self, node_features, edge_index)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    191\u001b[0m     node_features: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    192\u001b[0m     edge_index: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    193\u001b[0m ):\n\u001b[0;32m--> 194\u001b[0m     message, transformed_node_features, target_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_attention(\n\u001b[1;32m    195\u001b[0m         node_features\u001b[38;5;241m=\u001b[39mnode_features,\n\u001b[1;32m    196\u001b[0m         edge_index\u001b[38;5;241m=\u001b[39medge_index,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch_scatter\u001b[38;5;241m.\u001b[39mscatter_add(\n\u001b[1;32m    199\u001b[0m         message,\n\u001b[1;32m    200\u001b[0m         target_nodes,\n\u001b[1;32m    201\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    202\u001b[0m         dim_size\u001b[38;5;241m=\u001b[39mtransformed_node_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m transformed_node_features\n",
      "Cell \u001b[0;32mIn[6], line 173\u001b[0m, in \u001b[0;36mGraphAttentionLayerV3.compute_attention\u001b[0;34m(self, node_features, edge_index)\u001b[0m\n\u001b[1;32m    170\u001b[0m h_i \u001b[38;5;241m=\u001b[39m h[target_nodes]\n\u001b[1;32m    172\u001b[0m h_j \u001b[38;5;241m=\u001b[39m h[neighbors_nodes]\n\u001b[0;32m--> 173\u001b[0m h_concat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h_i, h_j], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    175\u001b[0m eij \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(h_concat), negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling)\n\u001b[1;32m    177\u001b[0m attention_score \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(\n\u001b[1;32m    178\u001b[0m     torch_scatter\u001b[38;5;241m.\u001b[39mscatter_softmax(\n\u001b[1;32m    179\u001b[0m         src\u001b[38;5;241m=\u001b[39meij,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[1;32m    184\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 364.00 MiB. GPU 0 has a total capacity of 3.63 GiB of which 179.00 MiB is free. Including non-PyTorch memory, this process has 2.71 GiB memory in use. Of the allocated memory 2.48 GiB is allocated by PyTorch, and 164.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "#multihead_gat_model = MultiheadGATModel(n_node_features=136,\n",
    "                                  # n_hidden_features=512,\n",
    "                                  # n_out_features=1,\n",
    "                                  # dropout=0.1,\n",
    "                                  # agg_method=\"mean\",\n",
    "                                  # num_heads=4)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gat_model = SimpleGATModel(n_node_features=50,\n",
    "                           n_hidden_features=50,\n",
    "                           n_out_features=121,\n",
    "                          )\n",
    "                           #dropout=0.1)\n",
    "\n",
    "#geom_model = models.GAT(in_channels=3, hidden_channels=12, num_layers=1, out_channels=1)\n",
    "#geom_model = GATGraphClassifier(in_channels=3, hidden_channels=12, num_layers=3, out_channels=1)\n",
    "history = train_model(model=gat_model,\n",
    "                      loss_fn=nn.BCEWithLogitsLoss(),\n",
    "                      train_loader=train_loader,\n",
    "                      valid_loader=val_loader,\n",
    "                      epochs=20,\n",
    "                      lr=5e-4,\n",
    "                      max_learning_rate=5e-3,\n",
    "                     weight_decay=1e-3,\n",
    "                      device=\"cuda\")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de086306-ec6a-4d68-b902-7286d53e82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd663253-dc22-4e55-82b3-69415c7aa254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = sns.lineplot(history, x=\"epoch\", y=\"train_loss\",color=\"green\")\n",
    "ax = sns.lineplot(history, x=\"epoch\", y=\"valid_loss\", color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c4a4e-d32f-4faa-a528-7d7c0bef8b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gat_model.eval()\n",
    "device=\"cpu\"\n",
    "gat_model.to(device)\n",
    "\n",
    "preds = []\n",
    "target_labels = []\n",
    "with torch.no_grad():\n",
    "    for test_batch in test_loader:\n",
    "        # Sort edges by target node to make scatter_softmax deterministic\n",
    "        sorted_idx = test_batch.edge_index[0].argsort()\n",
    "        edge_index_sorted = test_batch.edge_index[:, sorted_idx]\n",
    "\n",
    "        outputs = gat_model(node_features= test_batch.x, edge_index=edge_index_sorted, batch_vector=test_batch.batch).squeeze()\n",
    "        #preds.append(outputs)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds.append((probs > 0.5).int())\n",
    "        target_labels.append(test_batch.y)\n",
    "\n",
    "preds = torch.cat(preds)\n",
    "target_labels = torch.cat(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bfe27-59d0-4f49-b14d-b398b7ecd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c17c07-c2bf-4958-ab87-057455934b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13755f1-0179-453b-8755-2961a052cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MCC = {sk_metrics.matthews_corrcoef(target_labels, preds)}\")\n",
    "print(f\"ACC = {sk_metrics.accuracy_score(target_labels, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309f03e-f28f-45b5-915a-3c227532b020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"MAE = {sk_metrics.mean_absolute_error(target_labels, preds)}\")\n",
    "# print(f\"RMSE = {sk_metrics.root_mean_squared_error(target_labels, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f35d16-6737-4e15-84db-06175f3cdf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0318404a46e44235980e5638749a502f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "07905321525e496db5f6b0c3c64df878": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ea43164af77e438d89370224a37c37e9",
        "IPY_MODEL_723ffcc4240b47d697b116476e994e9d",
        "IPY_MODEL_4b475298901644849c90752cadcdf49d"
       ],
       "layout": "IPY_MODEL_8bead5d9ab534ff6b1710b2e3200115b"
      }
     },
     "0a34b3d700e446bf8e478a8157afca36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f3ff95861ae04f39be50e993e6ef953d",
       "style": "IPY_MODEL_5e11f94b292b4c5684c89502681c915d",
       "value": "â€‡0/10â€‡[06:27&lt;?,â€‡?it/s]"
      }
     },
     "0be6470cb44c43828fbf57073f636767": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0c0243348bd74f068b1b9afd97f331a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "11e45a17c12947bd87a67d28a203451c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_369454554e1a4f2fb6ac457f2f53d3c7",
       "max": 40,
       "style": "IPY_MODEL_196ac4a26d8b418b99f39d77cb3da008",
       "value": 40
      }
     },
     "1384dd511e5245939a76757ea4c34435": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "14d1d9681c9a4494931f0c0365023bb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ced22994139d49a897a21524d7780c57",
        "IPY_MODEL_11e45a17c12947bd87a67d28a203451c",
        "IPY_MODEL_68f45e35343b4747bb4e6d921934c0f2"
       ],
       "layout": "IPY_MODEL_8223bc826c7e405bbb5c7e256b84f47a"
      }
     },
     "1528afef076444958df148303eb8d09c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "17806d35978d46c4ae1ea9e1d9b2a2d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "196ac4a26d8b418b99f39d77cb3da008": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1cedb713c3db41ce862512ea2a15cc46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4cf8b06c68f44190b435b913607c7cb3",
        "IPY_MODEL_7728fdb208bc43a491ef9d269b5513df",
        "IPY_MODEL_0a34b3d700e446bf8e478a8157afca36"
       ],
       "layout": "IPY_MODEL_c770dd0b72a34475bed2df37a73806fa"
      }
     },
     "1efc1f8db42a4abbb0ea4c27e14ee02e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "239e683148f0466fb77f025c0894f539": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "25a0c3c6c9bb4d1d96ad1bf9a98ec7c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2ad01ef07afb4b269d48d7c1e34a6490": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2e7099d64fb64997bc4ae881e740e448": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_5270bd97c71346658068edf9ecec9dda",
       "max": 10,
       "style": "IPY_MODEL_9413f62b162f43b9b2ed68ffc1fc0ec8",
       "value": 1
      }
     },
     "2f58092b77274fbfa8a461db6daec803": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "31854dc41247485e95c694297a169ce1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7f313a3b82e04cd8b8e1751be965ab11",
       "style": "IPY_MODEL_94c23100befb412abed4c5709ee0366b",
       "value": "â€‡0/10â€‡[02:19&lt;?,â€‡?it/s]"
      }
     },
     "342f63cdf7da44628d7ddcf44f954da2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_bdb54b1d7dcd49a499381cdba3336052",
       "max": 10,
       "style": "IPY_MODEL_709ef80634fa41fe859bd70dace38504"
      }
     },
     "369454554e1a4f2fb6ac457f2f53d3c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36a91a60bb5245419c630b9bdfdaff7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39a6ee85757b4392a7c908ed518b73c9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3eb27859fab64e00b635a30362c72ef6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3f0ca3f9f29f43f6a639498617793ae6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_64e341eeb96843c990ad39b7f0835444",
        "IPY_MODEL_7e32dbe4915840399fc36cec6bcf8012",
        "IPY_MODEL_b097b827e2d44079a1b8358b27d2afe0"
       ],
       "layout": "IPY_MODEL_589e0cb22f5f45ae8b14ecd7d58edcbf"
      }
     },
     "4020ce3823d2441a9b7b1933553150d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40c111705c8940f7843ad4becf4b9a3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "42b21c29c55444a1bb052f4d3516edcb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4506ce39e0c243bca0e95b90916df4f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_766e776e512f4995b83e1ff19230c5cb",
        "IPY_MODEL_a51980fcd755404aa4a2c63102e1b160",
        "IPY_MODEL_750590a692524151aab0b539c6d27412"
       ],
       "layout": "IPY_MODEL_c62d726fff83438c8ea1037de8c0be91"
      }
     },
     "462270acd8384fa48c68599e02d6918a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "476c4e1d0c694a0eb645e4c08599734f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_25a0c3c6c9bb4d1d96ad1bf9a98ec7c6",
       "style": "IPY_MODEL_499532b149da4a6b924937ca376b735a",
       "value": "Training:â€‡100%"
      }
     },
     "48921c8bc7d74d42a9562eafd72f0b5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "499532b149da4a6b924937ca376b735a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "49ecfaa0b8ef4ae281a53425265c46a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_e5239006412d4027a45e3347f078796a",
       "max": 10,
       "style": "IPY_MODEL_806bd17b4e9646e1ba29270640871ec0"
      }
     },
     "4b475298901644849c90752cadcdf49d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8e01cba6f0c44557a685a2d0554f9786",
       "style": "IPY_MODEL_78c15e8051444824a01fff1cf72c2635",
       "value": "â€‡0/10â€‡[00:00&lt;?,â€‡?it/s]"
      }
     },
     "4bd6a36749464cfbac9eeae4c611dcda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4cf8b06c68f44190b435b913607c7cb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ca9895d8153948a1ba93e69b84569e67",
       "style": "IPY_MODEL_1384dd511e5245939a76757ea4c34435",
       "value": "Training:â€‡â€‡â€‡0%"
      }
     },
     "4da02ffa197e41259d9dd616264051c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bd02346f4a6d44518115c42f2976ff73",
       "style": "IPY_MODEL_b0b7f0d8f647439e8cfbb872d4c6e50a",
       "value": "â€‡10/10â€‡[01:04&lt;00:00,â€‡â€‡6.25s/it]"
      }
     },
     "516d53c0df4140f7a5aa74a3da940eea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_4020ce3823d2441a9b7b1933553150d3",
       "max": 50,
       "style": "IPY_MODEL_17806d35978d46c4ae1ea9e1d9b2a2d3",
       "value": 41
      }
     },
     "5270bd97c71346658068edf9ecec9dda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "589e0cb22f5f45ae8b14ecd7d58edcbf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "59b3ed3a20b94ba8b0ca31d317102adb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5e11f94b292b4c5684c89502681c915d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6140e603014f424abed9f575e5d56d56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a9e3bb49b5e348a1be01112031ed18f4",
        "IPY_MODEL_49ecfaa0b8ef4ae281a53425265c46a1",
        "IPY_MODEL_31854dc41247485e95c694297a169ce1"
       ],
       "layout": "IPY_MODEL_e4a44b38db0b4fd6a1cb0169ccfed349"
      }
     },
     "62228603bd21486b83ff0a57a05682e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_476c4e1d0c694a0eb645e4c08599734f",
        "IPY_MODEL_84629636da614eb98da7b211b3bfbc76",
        "IPY_MODEL_4da02ffa197e41259d9dd616264051c8"
       ],
       "layout": "IPY_MODEL_7303ee6f633a4b0b9b5c163da090daf7"
      }
     },
     "632ee9b83e0f401b920baa654a6ea5bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "64e341eeb96843c990ad39b7f0835444": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c5322344ae7d473e878c501a4825871b",
       "style": "IPY_MODEL_1528afef076444958df148303eb8d09c",
       "value": "Training:â€‡â€‡â€‡0%"
      }
     },
     "6872bb5e99e74d71affb4669ee171727": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_da073501deea4262b78bf22fab622fd9",
       "style": "IPY_MODEL_3eb27859fab64e00b635a30362c72ef6",
       "value": "Training:â€‡â€‡10%"
      }
     },
     "68f45e35343b4747bb4e6d921934c0f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2ad01ef07afb4b269d48d7c1e34a6490",
       "style": "IPY_MODEL_d26cf56002144986b42921cd8e3ecdfb",
       "value": "â€‡40/40â€‡[04:02&lt;00:00,â€‡â€‡5.91s/it]"
      }
     },
     "709ef80634fa41fe859bd70dace38504": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "723ffcc4240b47d697b116476e994e9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_836c3ce0ba584aaca7519dae2ac5b6e7",
       "max": 10,
       "style": "IPY_MODEL_8337865246cf4b238283c1426510bf25"
      }
     },
     "7303ee6f633a4b0b9b5c163da090daf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "750590a692524151aab0b539c6d27412": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0318404a46e44235980e5638749a502f",
       "style": "IPY_MODEL_f01a920fc76344a387fbc9f3f977df43",
       "value": "â€‡20/20â€‡[01:50&lt;00:00,â€‡â€‡5.04s/it]"
      }
     },
     "766e776e512f4995b83e1ff19230c5cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_48921c8bc7d74d42a9562eafd72f0b5a",
       "style": "IPY_MODEL_59b3ed3a20b94ba8b0ca31d317102adb",
       "value": "Training:â€‡100%"
      }
     },
     "7728fdb208bc43a491ef9d269b5513df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_e0597ccc58b84ed883c45da211164182",
       "max": 10,
       "style": "IPY_MODEL_e1c104e013a143fca4f7deeaa9d59c9b"
      }
     },
     "78c15e8051444824a01fff1cf72c2635": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "78cb0fa2cf3c4f0ab6dc915a0cdcd901": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7e32dbe4915840399fc36cec6bcf8012": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_a5300b6023fe4411a0f0277a378dd369",
       "max": 10,
       "style": "IPY_MODEL_0be6470cb44c43828fbf57073f636767"
      }
     },
     "7f313a3b82e04cd8b8e1751be965ab11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "806bd17b4e9646e1ba29270640871ec0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8223bc826c7e405bbb5c7e256b84f47a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8337865246cf4b238283c1426510bf25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "836c3ce0ba584aaca7519dae2ac5b6e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "84629636da614eb98da7b211b3bfbc76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b52a2b0724114ab2ab2d2502509d6548",
       "max": 10,
       "style": "IPY_MODEL_ea315718036242fb8aa755751b615e15",
       "value": 10
      }
     },
     "8bead5d9ab534ff6b1710b2e3200115b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8df1a6efefb54a5784fb4402f09bf239": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8e01cba6f0c44557a685a2d0554f9786": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "932e8c2b461244e8887de5b2c5d7c37b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ef27bd17aa164590814f2926b25f1bd0",
        "IPY_MODEL_516d53c0df4140f7a5aa74a3da940eea",
        "IPY_MODEL_eecd389881a4456e9011abc2f06bebd9"
       ],
       "layout": "IPY_MODEL_40c111705c8940f7843ad4becf4b9a3f"
      }
     },
     "9413f62b162f43b9b2ed68ffc1fc0ec8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "94c23100befb412abed4c5709ee0366b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a51980fcd755404aa4a2c63102e1b160": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_1efc1f8db42a4abbb0ea4c27e14ee02e",
       "max": 20,
       "style": "IPY_MODEL_2f58092b77274fbfa8a461db6daec803",
       "value": 20
      }
     },
     "a5300b6023fe4411a0f0277a378dd369": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a9e3bb49b5e348a1be01112031ed18f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ab56a6f93f43427fae53fe0405eeab90",
       "style": "IPY_MODEL_c4c1cad7c85a43b49246c7ed034d5c58",
       "value": "Training:â€‡â€‡â€‡0%"
      }
     },
     "aaa1735bbddd48959f1e4aa3a7a4bf5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab56a6f93f43427fae53fe0405eeab90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ace79c271b9b4cecb2084fb13f2d5b34": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "af26c30231d64113895bb15b34d626f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b097b827e2d44079a1b8358b27d2afe0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4bd6a36749464cfbac9eeae4c611dcda",
       "style": "IPY_MODEL_fb6c12e813414e349eeecfe1cb5b289d",
       "value": "â€‡0/10â€‡[03:57&lt;?,â€‡?it/s]"
      }
     },
     "b0b7f0d8f647439e8cfbb872d4c6e50a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b52a2b0724114ab2ab2d2502509d6548": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bb98cc00bf184f5484d4b7ae5285a5cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_462270acd8384fa48c68599e02d6918a",
       "style": "IPY_MODEL_42b21c29c55444a1bb052f4d3516edcb",
       "value": "Training:â€‡â€‡â€‡0%"
      }
     },
     "bd02346f4a6d44518115c42f2976ff73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bdb54b1d7dcd49a499381cdba3336052": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c4c1cad7c85a43b49246c7ed034d5c58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c5322344ae7d473e878c501a4825871b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c62d726fff83438c8ea1037de8c0be91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c75b6b091cff4057b934cd46a6dafec0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6872bb5e99e74d71affb4669ee171727",
        "IPY_MODEL_2e7099d64fb64997bc4ae881e740e448",
        "IPY_MODEL_d42f03a62cfa432591de6cc6eee2a92a"
       ],
       "layout": "IPY_MODEL_f9e7acbb2a8d4851bb44aeb280f43179"
      }
     },
     "c770dd0b72a34475bed2df37a73806fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ca9895d8153948a1ba93e69b84569e67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cde0914229b24539a32078d14e130289": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ced22994139d49a897a21524d7780c57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0c0243348bd74f068b1b9afd97f331a1",
       "style": "IPY_MODEL_f11eb1d29b6d4c208c21eb850dad131d",
       "value": "Training:â€‡100%"
      }
     },
     "d26cf56002144986b42921cd8e3ecdfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d42f03a62cfa432591de6cc6eee2a92a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39a6ee85757b4392a7c908ed518b73c9",
       "style": "IPY_MODEL_af26c30231d64113895bb15b34d626f6",
       "value": "â€‡1/10â€‡[01:10&lt;10:32,â€‡70.25s/it]"
      }
     },
     "d87729abce8940589033475775f41c2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ace79c271b9b4cecb2084fb13f2d5b34",
       "style": "IPY_MODEL_aaa1735bbddd48959f1e4aa3a7a4bf5b",
       "value": "â€‡0/10â€‡[00:00&lt;?,â€‡?it/s]"
      }
     },
     "da073501deea4262b78bf22fab622fd9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "dcce0d167ba14ba4abe506ae57859dea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_bb98cc00bf184f5484d4b7ae5285a5cd",
        "IPY_MODEL_342f63cdf7da44628d7ddcf44f954da2",
        "IPY_MODEL_d87729abce8940589033475775f41c2e"
       ],
       "layout": "IPY_MODEL_632ee9b83e0f401b920baa654a6ea5bc"
      }
     },
     "e0597ccc58b84ed883c45da211164182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1c104e013a143fca4f7deeaa9d59c9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e4a44b38db0b4fd6a1cb0169ccfed349": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e5239006412d4027a45e3347f078796a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ea315718036242fb8aa755751b615e15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ea43164af77e438d89370224a37c37e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_78cb0fa2cf3c4f0ab6dc915a0cdcd901",
       "style": "IPY_MODEL_239e683148f0466fb77f025c0894f539",
       "value": "Training:â€‡â€‡â€‡0%"
      }
     },
     "eecd389881a4456e9011abc2f06bebd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fb20f3c3f1e44a68917460039790be84",
       "style": "IPY_MODEL_36a91a60bb5245419c630b9bdfdaff7b",
       "value": "â€‡41/50â€‡[03:48&lt;00:54,â€‡â€‡6.05s/it]"
      }
     },
     "ef27bd17aa164590814f2926b25f1bd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cde0914229b24539a32078d14e130289",
       "style": "IPY_MODEL_8df1a6efefb54a5784fb4402f09bf239",
       "value": "Training:â€‡â€‡82%"
      }
     },
     "f01a920fc76344a387fbc9f3f977df43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f11eb1d29b6d4c208c21eb850dad131d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f3ff95861ae04f39be50e993e6ef953d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f9e7acbb2a8d4851bb44aeb280f43179": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb20f3c3f1e44a68917460039790be84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fb6c12e813414e349eeecfe1cb5b289d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
